# -*- coding: utf-8 -*-
"""prova-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D9QvfPuMjGtezX6PYp6HuDISpqO0Okcc
"""

from typing import Callable, List, Tuple

import os
import torch
import catalyst
from catalyst import utils

# print(f"torch: {torch.__version__}, catalyst: {catalyst.__version__}")

# os.environ["CUDA_VISIBLE_DEVICES"] = "0"
print(torch.cuda.is_available())

SEED = 42
utils.set_global_seed(SEED)
utils.prepare_cudnn(deterministic=True)

from pathlib import Path

ROOT = Path(os.getcwd()) / "drive" / "MyDrive" / "rene-polistico" / "dataset"

train_image_path = ROOT / "train"
train_mask_path = ROOT / "train_masks"
test_image_path = ROOT / "test"

ALL_IMAGES = sorted(
    [
        train_image_path / img
        for img in os.listdir(train_image_path)
        if img.endswith("jpg")
    ]
)
print(f"Images:{len(ALL_IMAGES)}")
ALL_IMAGES[:3]

ALL_MASKS = sorted(
    [
        train_mask_path / mask
        for mask in os.listdir(train_mask_path)
        if mask.endswith("png")
    ]
)
print(f"Masks:{len(ALL_MASKS)}")
ALL_MASKS[:3]

import random
import matplotlib.pyplot as plt
import numpy as np
from skimage.io import imread
from catalyst import utils


def show_examples(name: str, image: np.ndarray, mask: np.ndarray):
    plt.figure(figsize=(20, 28))
    plt.subplot(1, 2, 1)
    plt.imshow(image)
    plt.title(f"Image: {name}")

    plt.subplot(1, 2, 2)
    plt.imshow(mask)
    plt.title(f"Mask: {name}")


def show(index: int, images: List[Path], masks: List[Path], transforms=None) -> None:
    image_path = images[index]
    name = image_path.name
    image = utils.imread(image_path)
    mask = imread(train_mask_path / f"{os.path.splitext(name)[0]}_mask.png")
    #     mask = utils.imread(masks[index])

    if transforms is not None:
        temp = transforms(image=image, mask=mask)
        image = temp["image"]
        mask = temp["mask"]

    show_examples(name, image, mask)


def show_random(images: List[Path], masks: List[Path], transforms=None) -> None:
    length = len(images)
    index = random.randint(0, length - 1)
    show(index, images, masks, transforms)

from typing import List

from torch.utils.data import Dataset

class SegmentationDataset(Dataset):
    def __init__(
        self, images: List[Path], masks: List[Path] = None, transforms=None
    ) -> None:
        self.images = images
        self.masks = masks
        self.transforms = transforms

    def __len__(self) -> int:
        return len(self.images)

    def __getitem__(self, idx: int) -> dict:
        image_path = self.images[idx]
        name = image_path.name
        image = utils.imread(image_path)

        result = {"image": image}

        if self.masks is not None:
            mask = imread(train_mask_path / f"{os.path.splitext(name)[0]}_mask.png")
            result["mask"] = mask

        if self.transforms is not None:
            result = self.transforms(**result)

        result["filename"] = image_path.name

        return result

    show_random(ALL_IMAGES, ALL_MASKS)

import albumentations as albu
from albumentations.pytorch import ToTensor
from PIL import Image


def pre_transforms(image_size=224):
    return [albu.Resize(image_size, image_size, p=1)]


def hard_transforms():
    result = [
        albu.RandomRotate90(),
        albu.Cutout(),
        # albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),
        # albu.GridDistortion(p=0.3),
        # albu.HueSaturationValue(p=0.3),
    ]

    return result


def resize_transforms(image_size=224):
    BORDER_CONSTANT = 0
    pre_size = int(image_size * 1.5)

    random_crop = albu.Compose(
        [
            albu.SmallestMaxSize(pre_size, p=1),
            albu.RandomCrop(image_size, image_size, p=1),
        ]
    )

    rescale = albu.Compose([albu.Resize(image_size, image_size, p=1)])

    random_crop_big = albu.Compose(
        [
            albu.LongestMaxSize(pre_size, p=1),
            albu.RandomCrop(image_size, image_size, p=1),
        ]
    )

    # Converts the image to a square of size image_size x image_size
    result = [albu.OneOf([random_crop, rescale, random_crop_big], p=1)]

    return result


def post_transforms():
    # we use ImageNet image normalization
    # and convert it to torch.Tensor
    return [ToTensor()]


def compose(transforms_to_compose):
    # combine all augmentations into single pipeline
    result = albu.Compose(
        [item for sublist in transforms_to_compose for item in sublist]
    )
    return result


def show_random_transform(transforms):
    # transforms = compose([resize_transforms(), hard_transforms(), post_transforms()])
    length = len(ALL_IMAGES)
    index = random.randint(0, length - 1)
    IMG = ALL_IMAGES[index]
    
    plt.figure(figsize=(20, 28))
    plt.subplot(1, 2, 1)
    plt.imshow(utils.imread(IMG))
    plt.title(f"Image: {IMG}")
    
    transformed = transforms(image=utils.imread(IMG))
    transformed_image = transformed["image"]
    TRANSFORMED = np.moveaxis((np.array(transformed_image) * 255).astype("uint8"), 0, 2)

    plt.subplot(1, 2, 2)
    plt.imshow(Image.fromarray(TRANSFORMED))
    plt.title(f"Transformed")

    Image.fromarray(TRANSFORMED).save("prova.png")

train_transforms = albu.Compose(
    [
        # albu.RandomCrop(width=256, height=256),
        albu.Resize(256, 256),
        albu.HorizontalFlip(p=0.5),
        albu.RandomRotate90(),
        albu.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.6, p=0.5),
        # albu.GridDistortion(p=0.3),
        # albu.HueSaturationValue(p=0.5),
        ToTensor(),
    ]
)
# train_transforms = compose([resize_transforms(), hard_transforms(), post_transforms()])

show_random_transform(train_transforms)
show_random_transform(train_transforms)
show_random_transform(train_transforms)

# valid_transforms = compose([pre_transforms(), post_transforms()])

import collections
from sklearn.model_selection import train_test_split

from torch.utils.data import DataLoader


def get_loaders(
    images: List[Path],
    masks: List[Path],
    random_state: int,
    valid_size: float = 0.2,
    batch_size: int = 32,
    num_workers: int = 4,
    train_transforms_fn=None,
    valid_transforms_fn=None,
) -> dict:

    indices = np.arange(len(images))

    train_indices, valid_indices = train_test_split(
        indices, test_size=valid_size, random_state=random_state, shuffle=True
    )

    np_images = np.array(images)
    np_masks = np.array(masks)

    train_dataset = SegmentationDataset(
        images=np_images[train_indices].tolist(),
        masks=np_masks[train_indices].tolist(),
        transforms=train_transforms_fn,
    )
    
    valid_dataset = SegmentationDataset(
        images=np_images[train_indices].tolist(),
        masks=np_masks[train_indices].tolist(),
        transforms=train_transforms_fn,
    )
    
    print("batch_size", valid_transforms_fn)

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        drop_last=True,
    )

    valid_loader = DataLoader(
        valid_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        drop_last=True,
    )

    loaders = collections.OrderedDict()
    loaders["train"] = train_loader
    loaders["valid"] = valid_loader

    return loaders

batch_size = 32

loaders = get_loaders(
    images=ALL_IMAGES,
    masks=ALL_MASKS,
    random_state=SEED,
    train_transforms_fn=train_transforms,
    valid_transforms_fn=None,
    batch_size=batch_size,
)

import segmentation_models_pytorch as smp

model = smp.Unet(
    encoder_name="resnet50",
    encoder_weights="imagenet",
    in_channels=3,
    classes=1,
)

from torch import nn

from catalyst.contrib.nn import DiceLoss, IoULoss

criterion = {"dice": DiceLoss(), "iou": IoULoss(), "bce": nn.BCEWithLogitsLoss()}

from torch import optim

from catalyst.contrib.nn import RAdam, Lookahead

learning_rate = 0.00001
encoder_learning_rate = 0.0005

layerwise_params = {"encoder*": dict(lr=encoder_learning_rate, weight_decay=0.00003)}

model_params = utils.process_model_params(model, layerwise_params=layerwise_params)

base_optimizer = RAdam(model_params, lr=learning_rate, weight_decay=0.0003)
optimizer = Lookahead(base_optimizer)

scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.25, patience=2)

from catalyst.dl import SupervisedRunner

num_epochs = 100
logdir = "./logs/segmentation"

device = utils.get_device()
print(f"device: {device}")


# by default SupervisedRunner uses "features" and "targets",
runner = SupervisedRunner(device=device, input_key="image", input_target_key="mask")

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

from catalyst.dl import (
    DiceCallback,
    IouCallback,
    CriterionCallback,
    MetricAggregationCallback,
)
from catalyst.contrib.callbacks import DrawMasksCallback

callbacks = [
    CriterionCallback(input_key="mask", prefix="loss_dice", criterion_key="dice"),
    CriterionCallback(input_key="mask", prefix="loss_iou", criterion_key="iou"),
    CriterionCallback(input_key="mask", prefix="loss_bce", criterion_key="bce"),
    MetricAggregationCallback(
        prefix="loss",
        mode="weighted_sum",  # can be "sum", "weighted_sum" or "mean"
        metrics={"loss_dice": 1.0, "loss_iou": 1.0, "loss_bce": 0.8},
    ),
    # metrics
    DiceCallback(input_key="mask"),
    IouCallback(input_key="mask"),
    # visualization
    DrawMasksCallback(
        output_key="logits",
        input_image_key="image",
        input_mask_key="mask",
        summary_step=50,
    ),
]
#print("LOADER", num_epochs)

runner.train(
    model=model,
    criterion=criterion,
    optimizer=optimizer,
    scheduler=scheduler,
    loaders=loaders,
    callbacks=callbacks,
    # path to save logs
    logdir=logdir,
    num_epochs=num_epochs,
    main_metric="iou",
    minimize_metric=False,
    verbose=True,
)

TEST_IMAGES = sorted(train_image_path.glob("*.jpg"))

# create test dataset
test_dataset = SegmentationDataset(TEST_IMAGES, transforms=valid_transforms)

num_workers: int = 4

infer_loader = DataLoader(
    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers
)

# this get predictions for the whole loader
predictions = np.vstack(
    list(
        map(
            lambda x: x["logits"].cpu().numpy(),
            runner.predict_loader(
                loader=infer_loader, resume=f"{logdir}/checkpoints/best.pth"
            ),
        )
    )
)

print(type(predictions))
print(predictions.shape)

threshold = 0.5
max_count = 5

for i, (features, logits) in enumerate(zip(test_dataset, predictions)):
    image = utils.tensor_to_ndimage(features["image"])

    mask_ = torch.from_numpy(logits[0]).sigmoid()
    mask = utils.detach(mask_ > threshold).astype("float")

    show_examples(name="", image=image, mask=mask)

    if i >= max_count:
        break

batch = next(iter(loaders["valid"]))
# saves to `logdir` and returns a `ScriptModule` class
runner.trace(model=model, batch=batch, logdir=logdir, fp16=is_fp16_used)

!ls {logdir}/trace/

from catalyst.utils import tracing

if is_fp16_used:
    model = tracing.load_traced_model(
        f"{logdir}/trace/traced-forward-opt_O1.pth", 
        device="cuda", 
        opt_level="O1"
    )
else:
    model = tracing.load_traced_model(
        f"{logdir}/trace/traced-forward.pth", 
        device="cpu"
    )

model_input = batch["image"].to("cuda" if is_fp16_used else "cpu")
model(model_input)